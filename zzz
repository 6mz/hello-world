# -*- coding: utf-8 -*-
split.py
"""
import os, time, pickle, random, time
from datetime import datetime
import numpy as np
import math
from imageio import imwrite
import utils_align as utils_align

import glob
import cv2

def create_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

def analyse_raw_name(raw_name):
    raw_items = os.path.basename(raw_name).split("_")
    for i in range(len(raw_items)):
        if "ISO" == raw_items[i]:
            iso = int(raw_items[i+1])
    return iso

def analyse_ce_raw_name(raw_name):
    raw_items = os.path.basename(raw_name).split("_")
    iso = int(raw_items[5])

    return iso



def read_vogue_raw(raw_file, size):
    raw = np.fromfile(raw_file, dtype=np.uint16)
    raw = raw.reshape(size)
    
    #raw = raw_file
    row_num = raw.shape[0]
    column_num = raw.shape[1]

    img_b = raw[0:row_num:2, 0:column_num:2]
    img_gb = raw[0:row_num:2, 1:column_num:2]
    img_gr = raw[1:row_num:2, 0:column_num:2]
    img_r = raw[1:row_num:2, 1:column_num:2]

    img_test = np.stack([img_b, img_gb, img_gr, img_r], axis=-1)

    img_test = img_test / 1023.

    return img_test

def read_simple_raw(raw_file,size):
    raw = np.fromfile(raw_file,dtype=np.uint16)
    raw = raw.reshape(size)
    raw = raw / 1023.
    return raw


def crop_raw(raw,row,col):
    crop = raw[150:150+row-1,150:150+col-1]
    return crop

def calc_matrix(img1, img2):
    #first, find the sift features in images and apply the ratio test to find the best matches
    MIN_MATCH_COUNT = 10
    sift = cv2.xfeatures2d.SIFT_create()
    kp1, des1 = sift.detectAndCompute(img1,None)
    kp2, des2 = sift.detectAndCompute(img2,None)
    FLANN_INDEX_KDTREE = 0
    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
    search_params = dict(check = 50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    matchs = flann.knnMatch(des1,des2,k=2)	
    good = []
    for m,n in matchs:
    	if m.distance < 0.7*n.distance:
    		good.append(m)
    	
    #extract the locations of matched keypoints in both the images, and get the 3*3 transformation matrix
    if len(good)>MIN_MATCH_COUNT:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1,1,2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)
        #return M
    else:
        M = np.diag(np.diag(np.ones([3,3])))
    return M
    
def regis(raw,raw_tmp,shape):
    homo = calc_matrix(raw_tmp,raw)  #we need to warp raw_tmp to the position of raw
    raw_tmp = cv2.warpPerspective(raw_tmp,homo,shape,cv2.INTER_LINEAR,cv2.BORDER_REPLICATE)
    return raw_tmp
    
#10bit
def save_10bit_raw(input, path, size):
    row_num = size[0]
    column_num = size[1]
    rst_raw = np.ndarray(shape=size, dtype=np.float32)
    #print(rst_raw.shape)
    rst_raw[1:row_num:2, 1:column_num:2] = input[ :, :, 3]
    rst_raw[1:row_num:2, 0:column_num:2] = input[ :, :, 2]
    rst_raw[0:row_num:2, 1:column_num:2] = input[ :, :, 1]
    rst_raw[0:row_num:2, 0:column_num:2] = input[ :, :, 0]
    rst_raw = rst_raw * 1023

    rst_raw = np.where(rst_raw > 1023, 1023, rst_raw)
    rst_raw = rst_raw.astype(np.uint16)
    rst_raw.tofile(path)

    return 0

#10bit
def save_10bit_simple(input, path, size):
    #row_num = size[0]
    #column_num = size[1]
    rst_raw = np.ndarray(shape=size, dtype=np.float32)
    rst_raw = input * 1023.
    rst_raw = np.where(rst_raw > 1023, 1023, rst_raw)
    rst_raw = rst_raw.astype(np.uint16)
    rst_raw.tofile(path)

    return 0



def evaluate_net_v2(src_path, result_raw_path, folder_depth, test_items):

    # size= (2976, 3968)
    size = (2736, 3648)
    #size = (3648,2736)
    shape = (1824, 1368)

    src_folder_list = []
    dst_raw_path_list = []
    # for depth in folder_depth_list:
    #     tmp = sorted(glob.glob(src_path + "*/"*depth + "data_noise"))
    #     folder_list.extend(tmp)

    # test data bench mark
    for item in test_items:
        tmp = sorted(glob.glob(src_path + item + "*/"*folder_depth))
        src_folder_list.extend(tmp)
    for i in range(len(src_folder_list)):
        dst_raw_path_list.append(result_raw_path + src_folder_list[i][len(src_path):])

    reuse_flag = False

    loaded = False
    for i in range(len(src_folder_list)):
        print(src_folder_list[i])
        raw_files = glob.glob(src_folder_list[i] + '*.raw')
        raw_files.sort()
        raw_name = raw_files[0].split('/')[-1]
        prefix = raw_name.split('_')[0]
        
        create_dir(dst_raw_path_list[i])
        dst_raw_name = dst_raw_path_list[i] + prefix + '_' + raw_name[len(prefix):]

        frm_num = 4
        '''
        orig_raw_0 = read_vogue_raw(raw_files[frm_num-1],size)
        #print(orig_raw1.shape)
        save_10bit_raw(orig_raw_0, dst_raw_name, size)
        imwrite(dst_raw_path_list[i]+'_g_%d.png'% (frm_num-1), orig_raw_0[:,:,2])
        orig_raw_0 = np.clip(orig_raw_0, 0, 1)
        orig_raw_0 = orig_raw_0 * 255
        orig_raw_0 = orig_raw_0.astype(np.uint8)
        start_time = time.time()
        
        for f_tmp in range(0, frm_num-1):
            orig_raw_tmp = read_vogue_raw(raw_files[f_tmp],size)
             
            orig_raw_tmp = np.clip(orig_raw_tmp, 0, 1)
            orig_raw_tmp = 255*orig_raw_tmp
            orig_raw_tmp = orig_raw_tmp.astype(np.uint8)
            #orig_raw_tmp = regis(orig_raw_0, orig_raw_tmp1,size_3)
            
            homo = calc_matrix(orig_raw_0*2, orig_raw_tmp*2)  #we need to warp raw_tmp to the position of raw
            orig_raw_tmp = cv2.warpPerspective(orig_raw_tmp, homo, shape, cv2.INTER_LINEAR, cv2.BORDER_REPLICATE)
            
            
            orig_raw_tmp = orig_raw_tmp/(255.0)
            raw_name = raw_files[f_tmp+1].split('/')[-1]
            prefix = raw_name.split('_')[0]
            dst_raw_name = dst_raw_path_list[i] + prefix + '_' + raw_name[len(prefix):]
            save_10bit_raw(orig_raw_tmp, dst_raw_name, size)
            imwrite(dst_raw_path_list[i]+'_g_%d.png'% f_tmp, orig_raw_tmp[:,:,2])
            print(orig_raw_tmp.shape)

            print("process folder:%s" % src_folder_list[i])
            print("took: %4.4fs" % (time.time() - start_time))
            '''
        MOTION_MODEL = 'ECC'
        orig_raw = []
        orig_raw_G = []
        for f_tmp in range(0, frm_num):
            orig_raw_tmp = read_vogue_raw(raw_files[f_tmp],size)
            orig_raw_tmp = 255*orig_raw_tmp
            orig_raw_tmp = orig_raw_tmp.astype(np.uint8)
            orig_raw.append(orig_raw_tmp)
            orig_raw_G.append(orig_raw_tmp[:,:,1]*2)
        print('Start alignment')
        start_time = time.time()
        if MOTION_MODEL == 'ECC':
            t, t_inv, valid_id = utils_align.align_ecc(orig_raw, orig_raw_G, 0, thre=0.3)
        elif MOTION_MODEL == 'RIGID':
            t, t_inv, valid_id = utils_align.align_rigid(orig_raw, orig_raw_G, 0, thre=0.2)
        print("Full alignment: %4.4f" %(time.time() - start_time))
        
        orig_raw = [v.astype(np.float32)/255.0 for v in orig_raw]
        images_t, t, t_inv = utils_align.apply_transform(orig_raw, t, t_inv, MOTION_MODEL, scale=1)
        
        #crop
        is_crop = False#True
        if is_crop == True:
            min_h, max_h, min_w, max_w = 50, size[0]//2-50, 50, size[1]//2-50
            out_size = (2*(max_h-min_h), 2*(max_w-min_w))
        else:
            min_h, max_h, min_w, max_w = 0, size[0], 0, size[1]
            out_size = size
        ###
        for f_tmp in range(0, frm_num):
            img_tmp = images_t[f_tmp]
            
            img_tmp = img_tmp[min_h:max_h, min_w:max_w,:]
            raw_name = raw_files[f_tmp].split('/')[-1]
            prefix = raw_name.split('_')[0]
            dst_raw_name = dst_raw_path_list[i] + prefix + '_' + raw_name[len(prefix):]
            save_10bit_raw(img_tmp, dst_raw_name, out_size)
            imwrite(dst_raw_path_list[i]+MOTION_MODEL+'_g_%d.png'% f_tmp, img_tmp[:,:,2]*2)
        

    return 0

if __name__ == "__main__":
    test_items = ["20190703/"]
    #test_items = ["good/"]
    #test_items = ["test/"]
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"


    src_path = '/DATA1/dlnr_zcz/test_data/'#Log_20190322_1737/'

    #result_raw_path = '/DATA1/dlnr_zcz/test_data/after_registration/'
    result_raw_path = '/DATA1/dlnr_zcz/test_data/registration/20190703/input/'

    #evaluate_net(src_path, result_raw_path, gen_raw, gen_png, 1, net_dict, test_items)
    evaluate_net_v2(src_path, result_raw_path, 1, test_items)
    
    
    
    
    
##################    ultils_align.py######################
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import cv2
import numpy as np

def image_uint8(image):
    if image.max() > 10:
        return image
    image = (image * 255).astype(np.uint8)
    return image

def align_rigid(image_set, images_gray_set, ref_ind, thre=0.05):
    img_num = len(image_set)
    ref_gray_image = images_gray_set[ref_ind]
    r, c = image_set[0].shape[0:2]

    identity_transform = np.eye(2, 3, dtype=np.float32)
    warp_matrix = np.eye(2, 3, dtype=np.float32)
    tform_set_init = [np.eye(2, 3, dtype=np.float32)] * img_num

    tform_set = np.zeros_like(tform_set_init)
    tform_inv_set = np.zeros_like(tform_set_init)
    valid_id = []
    motion_thre = thre * min(r, c)
    for i in range(ref_ind - 1, -1, -1):
        warp_matrix = cv2.estimateRigidTransform(image_uint8(ref_gray_image), 
            image_uint8(images_gray_set[i]), fullAffine=0)
        if warp_matrix is None:
            continue
        tform_set[i] = warp_matrix
        tform_inv_set[i] = cv2.invertAffineTransform(warp_matrix)

        motion_val = abs(warp_matrix - identity_transform).sum()
        if motion_val < motion_thre:
            valid_id.append(i)
        else:
            continue

    warp_matrix = np.eye(2, 3, dtype=np.float32)
    for i in range(ref_ind, img_num, 1):
        warp_matrix = cv2.estimateRigidTransform(image_uint8(ref_gray_image), 
            image_uint8(images_gray_set[i]), fullAffine=0)
        if warp_matrix is None:
            tform_set[i] = identity_transform
            tform_inv_set[i] = identity_transform
            continue
        tform_set[i] = warp_matrix
        tform_inv_set[i] = cv2.invertAffineTransform(warp_matrix)
        motion_val = abs(warp_matrix - identity_transform).sum()
        if motion_val < motion_thre:
            valid_id.append(i)
        else:
            continue
    return tform_set, tform_inv_set, valid_id

def align_ecc(image_set, images_gray_set, ref_ind, thre=0.05):
    img_num = len(image_set)
    ref_gray_image = images_gray_set[ref_ind]
    r, c = image_set[0].shape[0:2]

    warp_mode = cv2.MOTION_AFFINE
    # cv2.MOTION_HOMOGRAPHY # cv2.MOTION_AFFINE # cv2.MOTION_TRANSLATION # cv2.MOTION_EUCLIDEAN

    # Define 2x3 or 3x3 matrices and initialize the matrix to identity
    if  warp_mode == cv2.MOTION_HOMOGRAPHY:
        print("Using homography model for alignment")
        identity_transform = np.eye(3, 3, dtype=np.float32)
        warp_matrix = np.eye(3, 3, dtype=np.float32)
        tform_set_init = [np.eye(3, 3, dtype=np.float32)] * img_num
    else:
        identity_transform = np.eye(2, 3, dtype=np.float32)
        warp_matrix = np.eye(2, 3, dtype=np.float32)
        tform_set_init = [np.eye(2, 3, dtype=np.float32)] * img_num

    number_of_iterations = 500
    termination_eps = 1e-6
    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)

    # Run the ECC algorithm. The results are stored in warp_matrix.
    tform_set = np.zeros_like(tform_set_init)
    tform_inv_set = np.zeros_like(tform_set_init)
    valid_id = []
    motion_thre = thre * min(r, c)
    for i in range(ref_ind - 1, -1, -1):
        _, warp_matrix = cv2.findTransformECC(ref_gray_image, images_gray_set[i], warp_matrix, warp_mode, criteria)
        tform_set[i] = warp_matrix
        tform_inv_set[i] = cv2.invertAffineTransform(warp_matrix)

        motion_val = abs(warp_matrix - identity_transform).sum()
        if motion_val < motion_thre:
            valid_id.append(i)
        else:
            continue

    if  warp_mode == cv2.MOTION_HOMOGRAPHY:
        warp_matrix = np.eye(3, 3, dtype=np.float32)
    else:
        warp_matrix = np.eye(2, 3, dtype=np.float32)

    for i in range(ref_ind, img_num, 1):
        _, warp_matrix = cv2.findTransformECC(ref_gray_image, images_gray_set[i], warp_matrix, warp_mode, criteria)
        tform_set[i] = warp_matrix
        tform_inv_set[i] = cv2.invertAffineTransform(warp_matrix)

        motion_val = abs(warp_matrix - identity_transform).sum()
        if motion_val < motion_thre:
            valid_id.append(i)
        else:
            continue
    return tform_set, tform_inv_set, valid_id

def apply_transform(image_set, tform_set, tform_inv_set, t_type, scale=1.):
    tform_set_2 = tform_set
    tform_inv_set_2 = tform_inv_set
    if t_type is None:
        if tform_set[0].shape == 2:
            t_type = "rigid"
        elif tform_set[0].shape == 3:
            t_type = "homography"
        else:
            print("[x] Invalid transforms")
            exit()

    r, c = image_set[0].shape[0:2]
    img_num = len(image_set)
    image_t_set = np.zeros_like(image_set)
    for i in range(img_num):
        image_i = image_set[i]
        tform_i = tform_set[i]
        tform_i_inv = tform_inv_set[i]
        tform_i[0,2] *= scale
        tform_i[1,2] *= scale
        tform_i_inv[0,2] *= scale
        tform_i_inv[1,2] *= scale
        tform_set_2[i] = tform_i
        tform_inv_set_2[i] = tform_i_inv
        if t_type != "homography":
            image_i_transform = cv2.warpAffine(image_i, tform_i, (c, r),
                                                flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)
        else:
            image_i_transform = cv2.warpPerspective(image_i, tform_i, (c, r),
                                                flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)
        image_t_set[i] = image_i_transform

    return image_t_set, tform_set_2, tform_inv_set_2

def sum_aligned_image(image_aligned, image_set):
    sum_img = np.float32(image_set[0]) * 1. / len(image_aligned)
    sum_img_t = np.float32(image_aligned[0]) * 1. / len(image_aligned)
    identity_transform = np.eye(2, 3, dtype=np.float32)
    r, c = image_set[0].shape[0:2]
    for i in range(1, len(image_aligned)):
        sum_img_t += np.float32(image_aligned[i]) * 1. / len(image_aligned)
        image_set_i = cv2.warpAffine(image_set[i], identity_transform, (c, r),
            flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)
        sum_img += np.float32(image_set_i) * 1. / len(image_aligned)
    return sum_img_t, sum_img

############################res.py######################
"""
res.py
"""
import os, time, pickle, random, time
from datetime import datetime
import numpy as np
import math
from imageio import imwrite
import utils_align as utils_align

import glob
import cv2

def create_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

def analyse_raw_name(raw_name):
    raw_items = os.path.basename(raw_name).split("_")
    for i in range(len(raw_items)):
        if "ISO" == raw_items[i]:
            iso = int(raw_items[i+1])
    return iso

def analyse_ce_raw_name(raw_name):
    raw_items = os.path.basename(raw_name).split("_")
    iso = int(raw_items[5])

    return iso



def read_vogue_raw(raw_file, size):
    raw = np.fromfile(raw_file, dtype=np.uint16)
    raw = raw.reshape(size)
    
    #raw = raw_file
    row_num = raw.shape[0]
    column_num = raw.shape[1]

    img_b = raw[0:row_num:2, 0:column_num:2]
    img_gb = raw[0:row_num:2, 1:column_num:2]
    img_gr = raw[1:row_num:2, 0:column_num:2]
    img_r = raw[1:row_num:2, 1:column_num:2]

    img_test = np.stack([img_b, img_gb, img_gr, img_r], axis=-1)

    img_test = img_test / 1023.

    return img_test

def read_simple_raw(raw_file,size):
    raw = np.fromfile(raw_file,dtype=np.uint16)
    raw = raw.reshape(size)
    raw = raw / 1023.
    return raw


def crop_raw(raw,row,col):
    crop = raw[150:150+row-1,150:150+col-1]
    return crop

def calc_matrix(img1, img2):
    #first, find the sift features in images and apply the ratio test to find the best matches
    MIN_MATCH_COUNT = 10
    sift = cv2.xfeatures2d.SIFT_create()
    kp1, des1 = sift.detectAndCompute(img1,None)
    kp2, des2 = sift.detectAndCompute(img2,None)
    FLANN_INDEX_KDTREE = 0
    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
    search_params = dict(check = 50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    matchs = flann.knnMatch(des1,des2,k=2)	
    good = []
    for m,n in matchs:
    	if m.distance < 0.7*n.distance:
    		good.append(m)
    	
    #extract the locations of matched keypoints in both the images, and get the 3*3 transformation matrix
    if len(good)>MIN_MATCH_COUNT:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1,1,2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)
        #return M
    else:
        M = np.diag(np.diag(np.ones([3,3])))
    return M
    
def regis(raw,raw_tmp,shape):
    homo = calc_matrix(raw_tmp,raw)  #we need to warp raw_tmp to the position of raw
    raw_tmp = cv2.warpPerspective(raw_tmp,homo,shape,cv2.INTER_LINEAR,cv2.BORDER_REPLICATE)
    return raw_tmp
    
#10bit
def save_10bit_raw(input, path, size):
    row_num = size[0]
    column_num = size[1]
    rst_raw = np.ndarray(shape=size, dtype=np.float32)
    #print(rst_raw.shape)
    rst_raw[1:row_num:2, 1:column_num:2] = input[ :, :, 3]
    rst_raw[1:row_num:2, 0:column_num:2] = input[ :, :, 2]
    rst_raw[0:row_num:2, 1:column_num:2] = input[ :, :, 1]
    rst_raw[0:row_num:2, 0:column_num:2] = input[ :, :, 0]
    rst_raw = rst_raw * 1023

    rst_raw = np.where(rst_raw > 1023, 1023, rst_raw)
    rst_raw = rst_raw.astype(np.uint16)
    rst_raw.tofile(path)

    return 0

#10bit
def save_10bit_simple(input, path, size):
    #row_num = size[0]
    #column_num = size[1]
    rst_raw = np.ndarray(shape=size, dtype=np.float32)
    rst_raw = input * 1023.
    rst_raw = np.where(rst_raw > 1023, 1023, rst_raw)
    rst_raw = rst_raw.astype(np.uint16)
    rst_raw.tofile(path)

    return 0



def evaluate_net_v2(src_path, result_raw_path, folder_depth, test_items):

    # size= (2976, 3968)
    size = (2736, 3648)
    #size = (3648,2736)
    shape = (1824, 1368)

    src_folder_list = []
    dst_raw_path_list = []
    # for depth in folder_depth_list:
    #     tmp = sorted(glob.glob(src_path + "*/"*depth + "data_noise"))
    #     folder_list.extend(tmp)

    # test data bench mark
    for item in test_items:
        tmp = sorted(glob.glob(src_path + item + "*/"*folder_depth))
        src_folder_list.extend(tmp)
    for i in range(len(src_folder_list)):
        dst_raw_path_list.append(result_raw_path + src_folder_list[i][len(src_path):])

    reuse_flag = False

    loaded = False
    for i in range(len(src_folder_list)):
        print(src_folder_list[i])
        raw_files = glob.glob(src_folder_list[i] + '*.raw')
        raw_files.sort()
        raw_name = raw_files[0].split('/')[-1]
        prefix = raw_name.split('_')[0]
        
        create_dir(dst_raw_path_list[i])
        dst_raw_name = dst_raw_path_list[i] + prefix + '_' + raw_name[len(prefix):]

        frm_num = 4
        '''
        orig_raw_0 = read_vogue_raw(raw_files[frm_num-1],size)
        #print(orig_raw1.shape)
        save_10bit_raw(orig_raw_0, dst_raw_name, size)
        imwrite(dst_raw_path_list[i]+'_g_%d.png'% (frm_num-1), orig_raw_0[:,:,2])
        orig_raw_0 = np.clip(orig_raw_0, 0, 1)
        orig_raw_0 = orig_raw_0 * 255
        orig_raw_0 = orig_raw_0.astype(np.uint8)
        start_time = time.time()
        
        for f_tmp in range(0, frm_num-1):
            orig_raw_tmp = read_vogue_raw(raw_files[f_tmp],size)
             
            orig_raw_tmp = np.clip(orig_raw_tmp, 0, 1)
            orig_raw_tmp = 255*orig_raw_tmp
            orig_raw_tmp = orig_raw_tmp.astype(np.uint8)
            #orig_raw_tmp = regis(orig_raw_0, orig_raw_tmp1,size_3)
            
            homo = calc_matrix(orig_raw_0*2, orig_raw_tmp*2)  #we need to warp raw_tmp to the position of raw
            orig_raw_tmp = cv2.warpPerspective(orig_raw_tmp, homo, shape, cv2.INTER_LINEAR, cv2.BORDER_REPLICATE)
            
            
            orig_raw_tmp = orig_raw_tmp/(255.0)
            raw_name = raw_files[f_tmp+1].split('/')[-1]
            prefix = raw_name.split('_')[0]
            dst_raw_name = dst_raw_path_list[i] + prefix + '_' + raw_name[len(prefix):]
            save_10bit_raw(orig_raw_tmp, dst_raw_name, size)
            imwrite(dst_raw_path_list[i]+'_g_%d.png'% f_tmp, orig_raw_tmp[:,:,2])
            print(orig_raw_tmp.shape)

            print("process folder:%s" % src_folder_list[i])
            print("took: %4.4fs" % (time.time() - start_time))
            '''
        MOTION_MODEL = 'ECC'
        orig_raw = []
        orig_raw_G = []
        for f_tmp in range(0, frm_num):
            orig_raw_tmp = read_vogue_raw(raw_files[f_tmp],size)
            orig_raw_tmp = 255*orig_raw_tmp
            orig_raw_tmp = orig_raw_tmp.astype(np.uint8)
            orig_raw.append(orig_raw_tmp)
            orig_raw_G.append(orig_raw_tmp[:,:,1]*2)
        print('Start alignment')
        start_time = time.time()
        if MOTION_MODEL == 'ECC':
            t, t_inv, valid_id = utils_align.align_ecc(orig_raw, orig_raw_G, 0, thre=0.3)
        elif MOTION_MODEL == 'RIGID':
            t, t_inv, valid_id = utils_align.align_rigid(orig_raw, orig_raw_G, 0, thre=0.2)
        print("Full alignment: %4.4f" %(time.time() - start_time))
        
        orig_raw = [v.astype(np.float32)/255.0 for v in orig_raw]
        images_t, t, t_inv = utils_align.apply_transform(orig_raw, t, t_inv, MOTION_MODEL, scale=1)
        
        #crop
        is_crop = False#True
        if is_crop == True:
            min_h, max_h, min_w, max_w = 50, size[0]//2-50, 50, size[1]//2-50
            out_size = (2*(max_h-min_h), 2*(max_w-min_w))
        else:
            min_h, max_h, min_w, max_w = 0, size[0], 0, size[1]
            out_size = size
        ###
        for f_tmp in range(0, frm_num):
            img_tmp = images_t[f_tmp]
            
            img_tmp = img_tmp[min_h:max_h, min_w:max_w,:]
            raw_name = raw_files[f_tmp].split('/')[-1]
            prefix = raw_name.split('_')[0]
            dst_raw_name = dst_raw_path_list[i] + prefix + '_' + raw_name[len(prefix):]
            save_10bit_raw(img_tmp, dst_raw_name, out_size)
            imwrite(dst_raw_path_list[i]+MOTION_MODEL+'_g_%d.png'% f_tmp, img_tmp[:,:,2]*2)
        

    return 0

if __name__ == "__main__":
    test_items = ["20190703/"]
    #test_items = ["good/"]
    #test_items = ["test/"]
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"


    src_path = '/DATA1/dlnr_zcz/test_data/'#Log_20190322_1737/'

    #result_raw_path = '/DATA1/dlnr_zcz/test_data/after_registration/'
    result_raw_path = '/DATA1/dlnr_zcz/test_data/registration/20190703/input/'

    #evaluate_net(src_path, result_raw_path, gen_raw, gen_png, 1, net_dict, test_items)
    evaluate_net_v2(src_path, result_raw_path, 1, test_items)
